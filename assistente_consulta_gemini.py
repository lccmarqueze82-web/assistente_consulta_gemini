import streamlit as st
from google import genai 
from google.genai.errors import APIError

st.set_page_config(page_title="Assistente de Consulta Gemini", layout="wide")

st.title("ü©∫ Assistente de Consulta Gemini")

# Inicializa o cliente Gemini
# A chave de API deve ser configurada em .streamlit/secrets.toml como
# GOOGLE_API_KEY="SUA_CHAVE_AQUI"
try:
    client = genai.Client(api_key=st.secrets["GOOGLE_API_KEY"])
except KeyError:
    st.error("ERRO: Chave 'GOOGLE_API_KEY' n√£o encontrada nos segredos do Streamlit. Por favor, adicione sua chave de API do Gemini em .streamlit/secrets.toml.")
    st.stop()
except Exception as e:
    st.error(f"ERRO ao inicializar o cliente Gemini: {e}")
    st.stop()

# Usaremos o modelo 'gemini-2.5-flash' ou outro modelo de chat/texto adequado.
GEMINI_MODEL = "gemini-2.5-flash" 

st.markdown("""
O assistente trabalha em 4 etapas:
1Ô∏è‚É£ **Caixa 1** ‚Äì Informa√ß√£o crua  
2Ô∏è‚É£ **Caixa 2** ‚Äì Aplica Prompt PEC1 atualizado  
3Ô∏è‚É£ **Caixa 3** ‚Äì Sugest√µes e condutas  
4Ô∏è‚É£ **Caixa 4** ‚Äì Chat livre com Gemini  
---
""")

# --- Fun√ß√£o de Chamada do Gemini (Mantida) ---
def gemini_reply(system_instruction, text_input):
    """Fun√ß√£o para chamar o modelo Gemini com instru√ß√µes de sistema."""
    
    # O SDK do Gemini usa 'system_instruction' no par√¢metro 'config'
    config = genai.types.GenerateContentConfig(
        system_instruction=system_instruction
    )
    
    try:
        response = client.models.generate_content(
            model=GEMINI_MODEL,
            contents=text_input, # O conte√∫do a ser processado pelo modelo
            config=config 
        )
        return response.text.strip()
    except APIError as e:
        st.error(f"Erro da API do Gemini: {e}")
        return f"ERRO NA API: {e}"
    except Exception as e:
        st.error(f"Erro inesperado: {e}")
        return f"ERRO INESPERADO: {e}"

# --- Fun√ß√µes de Callback ---

def clear_fields():
    """Callback para a fun√ß√£o LIMPAR: Reseta todos os campos de estado da sess√£o."""
    for key in ["caixa1","caixa2","caixa3","caixa4", "chat_response"]:
        st.session_state[key] = ""
    # st.rerun() n√£o √© necess√°rio em um callback, a mudan√ßa de estado j√° dispara a re-execu√ß√£o,
    # mas o Streamlit √© mais tolerante ao st.rerun() dentro de um callback.

def apply_pec1():
    """Callback para a Etapa 2: Aplica Prompt PEC1 e atualiza Caixa 2."""
    if not st.session_state.get("caixa1"):
        st.warning("A Caixa 1 est√° vazia. Insira a informa√ß√£o crua primeiro.")
        return

    with st.spinner("Aplicando Prompt PEC1..."):
        system_role_pec1 = "Voc√™ √© um assistente de processamento de texto. Sua tarefa √© aplicar o 'Prompt PEC1 atualizado' ao texto de entrada, formatando e estruturando-o conforme as diretrizes do PEC1."
        
        st.session_state["caixa2"] = gemini_reply(
            system_role_pec1,
            st.session_state["caixa1"]
        )
        st.success("‚úÖ Prompt aplicado!")

def generate_suggestions():
    """Callback para a Etapa 3: Gerar Sugest√µes e atualizar Caixa 3."""
    if not st.session_state.get("caixa2"):
        st.warning("A Caixa 2 est√° vazia. Aplique o Prompt PEC1 (Etapa 2) primeiro.")
        return

    with st.spinner("Analisando diagn√≥stico..."):
        system_role_sugestoes = "Voc√™ √© um assistente m√©dico de IA. Analise cuidadosamente o texto processado, que j√° est√° formatado com o Prompt PEC1, e gere sugest√µes de diagn√≥sticos diferenciais e condutas m√©dicas apropriadas. Seja claro, conciso e use linguagem m√©dica profissional."
        
        st.session_state["caixa3"] = gemini_reply(
            system_role_sugestoes,
            st.session_state["caixa2"]
        )
        st.success("‚úÖ Sugest√µes geradas!")

def send_chat():
    """Callback para a Etapa 4: Chat Livre e exibe resposta no Markdown."""
    if not st.session_state.get("caixa4"):
        st.warning("A Caixa 4 est√° vazia. Digite sua pergunta.")
        return

    with st.spinner("Respondendo..."):
        system_role_chat = "Voc√™ √© um assistente de chat geral e prestativo. Responda √† pergunta do usu√°rio. Mantenha o contexto de ser um assistente, mas responda de forma livre."
        
        resposta = gemini_reply(system_role_chat, st.session_state["caixa4"])
        # Armazenamos a resposta em um novo campo para exibi√ß√£o, para n√£o conflitar com a caixa de input
        st.session_state["chat_response"] = resposta
        
# --- Inicializa o estado de exibi√ß√£o (IMPORTANTE) ---
if "chat_response" not in st.session_state:
    st.session_state["chat_response"] = ""


# --- Layout das Caixas de Texto (usando st.session_state para pre-preencher) ---
col1, col2, col3 = st.columns(3)

with col1:
    # Usamos o valor do session_state, mas o key faz a m√°gica de sincronizar
    st.text_area("CAIXA 1 - Informa√ß√£o Crua", value=st.session_state.get("caixa1", ""), height=250, key="caixa1")

with col2:
    st.text_area("CAIXA 2 - Prompt PEC1 Atualizado", value=st.session_state.get("caixa2", ""), height=250, key="caixa2")

with col3:
    st.text_area("CAIXA 3 - Sugest√µes e Discuss√£o", value=st.session_state.get("caixa3", ""), height=250, key="caixa3")

st.text_input("CAIXA 4 - Chat com Gemini", value=st.session_state.get("caixa4", ""), key="caixa4")

# --- Layout dos Bot√µes (AGORA USANDO CALLBACKS) ---
colA, colB, colC = st.columns([1, 1, 2])

with colA:
    # AGORA USAMOS O CALLBACK clear_fields
    st.button("üßπ LIMPAR", on_click=clear_fields) 

with colB:
    if st.button("üìã COPIAR CAIXA 2"):
        st.write("Conte√∫do da Caixa 2 copiado (copie manualmente abaixo):")
        st.code(st.session_state.get("caixa2", "")) 

with colC:
    # O bot√£o AGORA usa on_click=apply_pec1
    st.button("‚öôÔ∏è Aplicar Prompt PEC1", on_click=apply_pec1)

# --- Bot√£o Etapa 3 (Tamb√©m usando Callback) ---
# Exibimos o bot√£o separadamente, e ele s√≥ aparece se a caixa 2 estiver preenchida.
if st.session_state.get("caixa2"):
    st.button("üí¨ Gerar Sugest√µes (Caixa 3)", on_click=generate_suggestions)

# --- Bot√£o Etapa 4 (Tamb√©m usando Callback) ---
# Exibimos o bot√£o de chat e, se a resposta existir, exibimos o resultado abaixo.
if st.session_state.get("caixa4"):
    st.button("üí≠ Enviar Chat (Caixa 4)", on_click=send_chat)

# --- Exibi√ß√£o do Resultado do Chat (Etapa 4) ---
if st.session_state.get("chat_response"):
    st.markdown("---")
    st.markdown(f"**Gemini:** {st.session_state['chat_response']}")
    st.markdown("---")
